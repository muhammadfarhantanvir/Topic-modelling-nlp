{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec505087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T10:29:47.941937Z",
     "start_time": "2023-08-31T10:29:20.540989Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca33151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T10:29:54.291166Z",
     "start_time": "2023-08-31T10:29:53.487951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Sales</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SOM_118_00055_FA163EF3DB12-1b43-e3615700-3dca9...</td>\n",
       "      <td>brot urlaub ihre mein name wie kann ich weiter...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SOM_TPF_00101_FA163E22F5B7-1af3-de819700-4197c...</td>\n",
       "      <td>einen schnen guten tag lauditag du stehst ja m...</td>\n",
       "      <td>0</td>\n",
       "      <td>lauditag stehst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SOM_141_00085_FA163E622DEB-1b45-68d0e700-3c9a0...</td>\n",
       "      <td>guten tag und herzlich willkommen bei o sie sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>eta kumpel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SOM_LUB_00112_FA163E22F5B7-1af3-dc815700-45c46...</td>\n",
       "      <td>hallo herzlich willkommen bei der service sie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bert bislang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SOM_AMV_00100_FA163E153AE3-1bb7-3f731700-3fe36...</td>\n",
       "      <td>hallo schnen guten tag mein name die firma ott...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>395</td>\n",
       "      <td>SOM_LUB_00246_FA163EF3DB12-1b43-e3615700-3be4f...</td>\n",
       "      <td>herzlich willkommen bei dem otto service sie s...</td>\n",
       "      <td>0</td>\n",
       "      <td>pending eingeschränkt eingeschränkt vorteilen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>396</td>\n",
       "      <td>SOM_VYD_00630_FA163ED88855-1bef-b9321700-412dc...</td>\n",
       "      <td>herzlich willkommen bei o mein name wie kann i...</td>\n",
       "      <td>0</td>\n",
       "      <td>bahnhofstraße bahnhof bahnhofstraße ttt inhous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>397</td>\n",
       "      <td>SOM_LUB_00379_FA163E622DEB-1b45-6850d700-3e961...</td>\n",
       "      <td>herzlich willkommen bei o sie sprechen mit ihr...</td>\n",
       "      <td>0</td>\n",
       "      <td>rücksetzung aufgehängt rücksetzung frühen gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>398</td>\n",
       "      <td>SOM_TPF_00515_FA163E56E95C-1b1d-4929d700-3aab3...</td>\n",
       "      <td>herzlich willkommen bei blau ich werde am buck...</td>\n",
       "      <td>1</td>\n",
       "      <td>mso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>399</td>\n",
       "      <td>SOM_TPF_00410_FA163E622DEB-1b45-6850d700-40380...</td>\n",
       "      <td>herzlich willkommen bei ihrem o service sie sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>warner sofia sofia vollzogen sofia sophia stoh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1998 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          file_name  \\\n",
       "0              0  SOM_118_00055_FA163EF3DB12-1b43-e3615700-3dca9...   \n",
       "1              1  SOM_TPF_00101_FA163E22F5B7-1af3-de819700-4197c...   \n",
       "2              2  SOM_141_00085_FA163E622DEB-1b45-68d0e700-3c9a0...   \n",
       "3              3  SOM_LUB_00112_FA163E22F5B7-1af3-dc815700-45c46...   \n",
       "4              4  SOM_AMV_00100_FA163E153AE3-1bb7-3f731700-3fe36...   \n",
       "...          ...                                                ...   \n",
       "1993         395  SOM_LUB_00246_FA163EF3DB12-1b43-e3615700-3be4f...   \n",
       "1994         396  SOM_VYD_00630_FA163ED88855-1bef-b9321700-412dc...   \n",
       "1995         397  SOM_LUB_00379_FA163E622DEB-1b45-6850d700-3e961...   \n",
       "1996         398  SOM_TPF_00515_FA163E56E95C-1b1d-4929d700-3aab3...   \n",
       "1997         399  SOM_TPF_00410_FA163E622DEB-1b45-6850d700-40380...   \n",
       "\n",
       "                                                   text  Sales  \\\n",
       "0     brot urlaub ihre mein name wie kann ich weiter...      0   \n",
       "1     einen schnen guten tag lauditag du stehst ja m...      0   \n",
       "2     guten tag und herzlich willkommen bei o sie sp...      0   \n",
       "3     hallo herzlich willkommen bei der service sie ...      0   \n",
       "4     hallo schnen guten tag mein name die firma ott...      0   \n",
       "...                                                 ...    ...   \n",
       "1993  herzlich willkommen bei dem otto service sie s...      0   \n",
       "1994  herzlich willkommen bei o mein name wie kann i...      0   \n",
       "1995  herzlich willkommen bei o sie sprechen mit ihr...      0   \n",
       "1996  herzlich willkommen bei blau ich werde am buck...      1   \n",
       "1997  herzlich willkommen bei ihrem o service sie sp...      0   \n",
       "\n",
       "                                          filtered_text  \n",
       "0                                                   NaN  \n",
       "1                                       lauditag stehst  \n",
       "2                                            eta kumpel  \n",
       "3                                          bert bislang  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1993      pending eingeschränkt eingeschränkt vorteilen  \n",
       "1994  bahnhofstraße bahnhof bahnhofstraße ttt inhous...  \n",
       "1995  rücksetzung aufgehängt rücksetzung frühen gene...  \n",
       "1996                                                mso  \n",
       "1997  warner sofia sofia vollzogen sofia sophia stoh...  \n",
       "\n",
       "[1998 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset \n",
    "df = pd.read_excel('labeled_data_whole.xlsx')\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Remove special characters and numbers\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "# Print the preprocessed dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25feafeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T11:38:12.123647Z",
     "start_time": "2023-08-30T11:38:12.111543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brot urlaub ihre mein name wie kann ich weiterhelfen \\n  ja sind sie bei mir leider verkehrt ich leit direkt an die kollegen weiter nicht auflegen \\n  das wre optimal ja dann gebe ich den kollegen das weiter \\n  jetzt leite sie weiter ja nicht auflegen bitte tschau'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc469d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T09:21:34.869031Z",
     "start_time": "2023-08-30T09:21:34.862179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'einen schnen guten tag lauditag du stehst ja mein name wie kann ich ihnen helfen\\n ja\\n o k geht es um den rufnummer am ende\\n sie wollen diese prepaid karte registrieren richtig\\n also bei der persnliche kundenkennzahl knnen sie eine stellige nummer hinterlegen was sie wollen\\n einfach eine stellige nummer ja\\n ja haben sie vielleicht weitere fragen\\n o k\\n nee nee nee das ist so sie selbst hinterlegen o k dann wenn sie keine weitere fragen haben wnsche ich ihnen das war leicht schnen tag noch\\n tschss'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cce19b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T10:32:03.056042Z",
     "start_time": "2023-08-31T10:30:13.824096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Sales</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SOM_118_00055_FA163EF3DB12-1b43-e3615700-3dca9...</td>\n",
       "      <td>brot urlaub ihre mein name wie kann ich weiter...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SOM_TPF_00101_FA163E22F5B7-1af3-de819700-4197c...</td>\n",
       "      <td>einen schnen guten tag lauditag du stehst ja m...</td>\n",
       "      <td>0</td>\n",
       "      <td>lauditag stehst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SOM_141_00085_FA163E622DEB-1b45-68d0e700-3c9a0...</td>\n",
       "      <td>guten tag und herzlich willkommen bei sie spre...</td>\n",
       "      <td>0</td>\n",
       "      <td>eta kumpel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SOM_LUB_00112_FA163E22F5B7-1af3-dc815700-45c46...</td>\n",
       "      <td>herzlich willkommen bei der service sie sprech...</td>\n",
       "      <td>0</td>\n",
       "      <td>bert bislang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SOM_AMV_00100_FA163E153AE3-1bb7-3f731700-3fe36...</td>\n",
       "      <td>hallo schnen guten tag mein name die firma was...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          file_name  \\\n",
       "0           0  SOM_118_00055_FA163EF3DB12-1b43-e3615700-3dca9...   \n",
       "1           1  SOM_TPF_00101_FA163E22F5B7-1af3-de819700-4197c...   \n",
       "2           2  SOM_141_00085_FA163E622DEB-1b45-68d0e700-3c9a0...   \n",
       "3           3  SOM_LUB_00112_FA163E22F5B7-1af3-dc815700-45c46...   \n",
       "4           4  SOM_AMV_00100_FA163E153AE3-1bb7-3f731700-3fe36...   \n",
       "\n",
       "                                                text  Sales    filtered_text  \n",
       "0  brot urlaub ihre mein name wie kann ich weiter...      0              NaN  \n",
       "1  einen schnen guten tag lauditag du stehst ja m...      0  lauditag stehst  \n",
       "2  guten tag und herzlich willkommen bei sie spre...      0       eta kumpel  \n",
       "3  herzlich willkommen bei der service sie sprech...      0     bert bislang  \n",
       "4  hallo schnen guten tag mein name die firma was...      0              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the spaCy German language model\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "# Create an empty list to store the updated text without proper names\n",
    "updated_texts = []\n",
    "# Iterate over the text column and remove proper names using spaCy\n",
    "for text in df['text']:\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.pos_ != 'PROPN':\n",
    "            tokens.append(token.text)\n",
    "    updated_texts.append(' '.join(tokens))\n",
    "# Update the 'text' column with the modified text\n",
    "df['text'] = updated_texts\n",
    "\n",
    "# Print the updated dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542cb9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T10:33:58.796403Z",
     "start_time": "2023-08-31T10:33:58.788873Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_1 = df[df['Sales'] == 1]['text']\n",
    "sales_0 = df[df['Sales'] == 0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b711ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T10:34:01.025830Z",
     "start_time": "2023-08-31T10:34:01.020449Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sales_1 = pd.DataFrame({'text': sales_1})\n",
    "df_sales_0 = pd.DataFrame({'text': sales_0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cacdadbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T11:11:03.479160Z",
     "start_time": "2023-08-31T11:11:03.473000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales: 23.223223223223226\n",
      "Non sales: 76.77677677677679\n"
     ]
    }
   ],
   "source": [
    "total_sales_text = len(df_sales_1)\n",
    "total_non_sales_text = len(df_sales_0)\n",
    "total = len(df['text'] )\n",
    "dist_for_sales = total_sales_text/ total\n",
    "dist_for_non_sales = total_non_sales_text/ total\n",
    "\n",
    "print('sales:',dist_for_sales* 100)\n",
    "print('Non sales:',dist_for_non_sales* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a69d20cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T11:13:33.003433Z",
     "start_time": "2023-08-31T11:13:27.028107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verkauf topics: 89.39%\n",
      "Vertrag topics: 99.05%\n",
      "Dienstleistung topics: 78.73%\n",
      "Beschwerden topics: 95.65%\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and create a dictionary\n",
    "# Topic for text\n",
    "texts = [el.split() for el in list(df[\"text\"].to_numpy())]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Perform LDA\n",
    "num_topics = 4\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Extract topic distributions and labels\n",
    "topic_distributions = [lda_model.get_document_topics(text) for text in corpus]\n",
    "topic_labels = [\"Verkauf\", \"Dienstleistung\", \"Beschwerden\", \"Vertrag\"]\n",
    "\n",
    "# Calculate percentage distribution\n",
    "total_documents_text = len(topic_distributions)\n",
    "topic_counts = Counter([topic for doc_topics in topic_distributions for topic, _ in doc_topics])\n",
    "topic_percentages = {label: (count / total_documents_text) * 100 for label, count in topic_counts.items()}\n",
    "\n",
    "# Print the percentage distribution for each topic\n",
    "for label, percentage in topic_percentages.items():\n",
    "    topic_label = topic_labels[label]\n",
    "    print(f\"{topic_label.capitalize()} topics: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9166de9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T11:14:01.476718Z",
     "start_time": "2023-08-31T11:13:59.690964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verkauf topics: 16.52%\n",
      "Dienstleistung topics: 22.57%\n",
      "Vertrag topics: 23.07%\n",
      "Beschwerden topics: 22.32%\n"
     ]
    }
   ],
   "source": [
    "# Topic for sales category\n",
    "# Tokenize and create a dictionary\n",
    "texts = [el.split() for el in list(df_sales_1[\"text\"].to_numpy())]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Perform LDA\n",
    "num_topics = 4\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Extract topic distributions and labels\n",
    "topic_distributions = [lda_model.get_document_topics(df_sales_1) for df_sales_1 in corpus]\n",
    "topic_labels = [\"Verkauf\", \"Dienstleistung\", \"Beschwerden\", \"Vertrag\"]\n",
    "\n",
    "# Calculate percentage distribution\n",
    "total_documents = len(topic_distributions)\n",
    "topic_counts = Counter([topic for doc_topics in topic_distributions for topic, _ in doc_topics])\n",
    "topic_percentages = {label: (count / total_documents_text) * 100 for label, count in topic_counts.items()}\n",
    "\n",
    "# Print the percentage distribution for each topic\n",
    "for label, percentage in topic_percentages.items():\n",
    "    topic_label = topic_labels[label]  # Get the corresponding label\n",
    "    print(f\"{topic_label.capitalize()} topics: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "044393af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T11:13:49.628221Z",
     "start_time": "2023-08-31T11:13:45.278895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verkauf topics: 70.62%\n",
      "Beschwerden topics: 50.65%\n",
      "Vertrag topics: 75.58%\n",
      "Dienstleistung topics: 4.10%\n"
     ]
    }
   ],
   "source": [
    "# Topic for Non sales category\n",
    "# Tokenize and create a dictionary\n",
    "# texts = [df_sales_0.split() for df_sales_0 in df_sales_0]\n",
    "texts = [el.split() for el in list(df_sales_0[\"text\"].to_numpy())]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Perform LDA\n",
    "num_topics = 4\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Extract topic distributions and labels\n",
    "topic_distributions = [lda_model.get_document_topics(df_sales_0) for df_sales_0 in corpus]\n",
    "topic_labels = [\"Verkauf\", \"Dienstleistung\", \"Beschwerden\", \"Vertrag\"]\n",
    "\n",
    "# Calculate percentage distribution\n",
    "total_documents = len(topic_distributions)\n",
    "topic_counts = Counter([topic for doc_topics in topic_distributions for topic, _ in doc_topics])\n",
    "topic_percentages = {label: (count / total_documents_text) * 100 for label, count in topic_counts.items()}\n",
    "\n",
    "# Print the percentage distribution for each topic\n",
    "for label, percentage in topic_percentages.items():\n",
    "    topic_label = topic_labels[label]  # Get the corresponding label\n",
    "    print(f\"{topic_label.capitalize()} topics: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a774e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T09:48:06.226000Z",
     "start_time": "2023-08-26T09:48:06.222006Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad4a0d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T09:48:18.877529Z",
     "start_time": "2023-08-26T09:48:18.873621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing steps (you can customize this based on your requirements)\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = text.lower().replace('[^\\w\\s]', '')\n",
    "    # Remove stopwords (you may need to download the stopwords list)\n",
    "    stopwords = set(stopwords.words('german'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eddfce",
   "metadata": {},
   "source": [
    " <h5> Contextualized Topic Models </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45f95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
